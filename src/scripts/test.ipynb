{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc496cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c7be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f832411",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_DIR = \"/user/solovyovyu/geo.csv\"\n",
    "EVENTS_DIR = \"/user/master/data/geo/events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c45ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/12 08:58:30 WARN Utils: Your hostname, fhmm5ka5efrhqhnrskjc resolves to a loopback address: 127.0.1.1; using 172.16.0.8 instead (on interface eth0)\n",
      "25/01/12 08:58:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/12 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/12 08:58:33 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "25/01/12 08:58:56 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1729228596238_9999_01_000003 on host: rc1a-dataproc-d-jysa8rey4rqmgffj.mdb.yandexcloud.net. Exit status: 137. Diagnostics: [2025-01-12 08:58:53.846]Container killed on request. Exit code is 137\n",
      "[2025-01-12 08:58:53.846]Container exited with a non-zero exit code 137. \n",
      "[2025-01-12 08:58:53.846]Killed by external signal\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"yarn\").appName(\"Test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180634ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = spark.read.options(delimiter=\";\", header=True).csv(GEO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f31dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+--------+\n",
      "| id|      city|     lat|     lng|\n",
      "+---+----------+--------+--------+\n",
      "|  1|    Sydney| -33,865|151,2094|\n",
      "|  2| Melbourne|-37,8136|144,9631|\n",
      "|  3|  Brisbane|-27,4678|153,0281|\n",
      "|  4|     Perth|-31,9522|115,8589|\n",
      "|  5|  Adelaide|-34,9289|138,6011|\n",
      "|  6|Gold Coast|-28,0167|   153,4|\n",
      "|  7|Cranbourne|-38,0996|145,2834|\n",
      "|  8|  Canberra|-35,2931|149,1269|\n",
      "|  9| Newcastle|-32,9167|  151,75|\n",
      "| 10|Wollongong|-34,4331|150,8831|\n",
      "| 11|   Geelong|  -38,15|  144,35|\n",
      "| 12|    Hobart|-42,8806| 147,325|\n",
      "| 13|Townsville|-19,2564|146,8183|\n",
      "| 14|   Ipswich|-27,6167|152,7667|\n",
      "| 15|    Cairns|-16,9303|145,7703|\n",
      "| 16| Toowoomba|-27,5667|  151,95|\n",
      "| 17|    Darwin|-12,4381|130,8411|\n",
      "| 18|  Ballarat|  -37,55|  143,85|\n",
      "| 19|   Bendigo|  -36,75|144,2667|\n",
      "| 20|Launceston|-41,4419| 147,145|\n",
      "+---+----------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "geo_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76c28ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "events_df = spark.read.parquet(EVENTS_DIR).sample(fraction=0.001, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d615283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46518"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b1b4257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:===================================================>(1467 + 1) / 1468]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------------+------------------+\n",
      "|summary|  event_type|                lat|               lon|\n",
      "+-------+------------+-------------------+------------------+\n",
      "|  count|       46518|              10779|             10779|\n",
      "|   mean|        NULL| -30.52615460800812| 145.1872113815097|\n",
      "| stddev|        NULL|  7.698984345814036|10.269018749797446|\n",
      "|    min|     message| -42.88038839514516|115.63542765813348|\n",
      "|    max|subscription|-11.438182591968504|154.39968710472294|\n",
      "+-------+------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "events_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05d145f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- admins: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- channel_id: long (nullable = true)\n",
      " |    |-- datetime: string (nullable = true)\n",
      " |    |-- media: struct (nullable = true)\n",
      " |    |    |-- media_type: string (nullable = true)\n",
      " |    |    |-- src: string (nullable = true)\n",
      " |    |-- message: string (nullable = true)\n",
      " |    |-- message_channel_to: long (nullable = true)\n",
      " |    |-- message_from: long (nullable = true)\n",
      " |    |-- message_group: long (nullable = true)\n",
      " |    |-- message_id: long (nullable = true)\n",
      " |    |-- message_to: long (nullable = true)\n",
      " |    |-- message_ts: string (nullable = true)\n",
      " |    |-- reaction_from: string (nullable = true)\n",
      " |    |-- reaction_type: string (nullable = true)\n",
      " |    |-- subscription_channel: long (nullable = true)\n",
      " |    |-- subscription_user: string (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
