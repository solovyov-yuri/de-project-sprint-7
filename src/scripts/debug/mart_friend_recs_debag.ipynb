{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "612e1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from logger import LoggerConfig\n",
    "from logging import Logger\n",
    "from pyspark.sql import SparkSession, DataFrame, functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import DoubleType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67469c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1e45cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEV Constants\n",
    "GEO_DIR = \"/user/solovyovyu/geo.csv\"\n",
    "EVENTS_DIR = \"/user/master/data/geo/events\"\n",
    "OUT_PATH = \"/user/solovyovyu/analytics\"\n",
    "# CUR_DATE = \"2022-01-02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfe9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LoggerConfig.get_logger(\"Friend Recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "99f790bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events(event_type: str, events_dir: str, spark: SparkSession, logger: Logger, date: str = \"*\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Read events from parquet file by partitions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = (\n",
    "            spark.read.parquet(f\"{events_dir}/date={date}/event_type={event_type}\")\n",
    "            .where(F.col(\"lat\").isNotNull() & F.col(\"lon\").isNotNull())\n",
    "            .select(\n",
    "                F.col(\"event.message_id\"),\n",
    "                F.coalesce(F.col(\"event.message_from\"), F.col(\"event.reaction_from\"), F.col(\"event.user\")).alias(\"user_id\"),\n",
    "                F.col(\"event.message_to\"),\n",
    "                F.coalesce(F.col(\"event.message_ts\"), F.col(\"event.datetime\")).alias(\"datetime\"),\n",
    "                \"lat\",\n",
    "                \"lon\",\n",
    "                \"event.subscription_channel\",\n",
    "            )\n",
    "        )\n",
    "        logger.info(f\"Events {event_type} are read from {events_dir}.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while reading events: {e}\")\n",
    "        raise\n",
    "\n",
    "        \n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Радиус Земли в километрах\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "\n",
    "@pandas_udf(DoubleType())\n",
    "def haversine_udf(lat1: pd.Series, lon1: pd.Series, lat2: pd.Series, lon2: pd.Series) -> pd.Series:\n",
    "    return haversine(lat1, lon1, lat2, lon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68cef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/17 12:07:42 WARN Utils: Your hostname, fhmtnvvm71dpggrdk8kg resolves to a loopback address: 127.0.1.1; using 172.16.0.22 instead (on interface eth0)\n",
      "25/02/17 12:07:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/17 12:07:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 12:07:45,277 - Mart Zones - INFO - SparkSession successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Create Spark session\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"Friend Recommendations\").getOrCreate()\n",
    "    logger.info(\"SparkSession successfully created.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating SparkSession: {e}\", exc_info=True)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/17 14:53:31 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n",
      "[Stage 278:=======>                                            (221 + 4) / 1468]\r"
     ]
    }
   ],
   "source": [
    "subscriptions_df = read_events(\"subscription\", EVENTS_DIR, spark, logger)\n",
    "\n",
    "subscriptions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f867dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- admins: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- channel_id: long (nullable = true)\n",
      " |    |-- datetime: string (nullable = true)\n",
      " |    |-- media: struct (nullable = true)\n",
      " |    |    |-- media_type: string (nullable = true)\n",
      " |    |    |-- src: string (nullable = true)\n",
      " |    |-- message: string (nullable = true)\n",
      " |    |-- message_channel_to: long (nullable = true)\n",
      " |    |-- message_from: long (nullable = true)\n",
      " |    |-- message_group: long (nullable = true)\n",
      " |    |-- message_id: long (nullable = true)\n",
      " |    |-- message_to: long (nullable = true)\n",
      " |    |-- message_ts: string (nullable = true)\n",
      " |    |-- reaction_from: string (nullable = true)\n",
      " |    |-- reaction_type: string (nullable = true)\n",
      " |    |-- subscription_channel: long (nullable = true)\n",
      " |    |-- subscription_user: string (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages_df = spark.read.parquet(f\"{EVENTS_DIR}/date={CUR_DATE}\")\n",
    "\n",
    "messages_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4346da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_subs_pairs = (\n",
    "    subscriptions_df.alias(\"a\")\n",
    "        .join(subscriptions_df.alias(\"b\"), on=\"subscription_channel\")\n",
    "        .filter(F.col(\"a.user_id\") < F.col(\"b.user_id\"))\n",
    "        .select(\n",
    "            F.col(\"a.user_id\").alias(\"user_left\"),\n",
    "            F.col(\"b.user_id\").alias(\"user_right\"),\n",
    "            F.col(\"a.subscription_channel\")\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ce292d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_chats = (\n",
    "    messages_df.select(\n",
    "        F.col(\"event.message_from\").alias(\"user_a\"),\n",
    "        F.col(\"event.message_to\").alias(\"user_b\")\n",
    "    ).union(messages_df.select(\n",
    "        F.col(\"event.message_to\").alias(\"user_a\"),\n",
    "        F.col(\"event.message_from\").alias(\"user_a\")\n",
    "    )).distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e2934514",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_recommendations = (\n",
    "    user_subs_pairs\n",
    "    .join(user_chats, (user_subs_pairs.user_left == user_chats.user_a) & (user_subs_pairs.user_right == user_chats.user_b), \"left_anti\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7195c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+\n",
      "|user_left|user_right|subscription_channel|\n",
      "+---------+----------+--------------------+\n",
      "|    52501|     92869|              663092|\n",
      "|    52501|     62096|              663092|\n",
      "|    52501|     57399|              663092|\n",
      "|    52957|     90674|              441039|\n",
      "|    52957|      8695|              441039|\n",
      "|    53221|     97429|               43023|\n",
      "|    53221|     71537|               43023|\n",
      "|    69558|     78890|              248680|\n",
      "|    69558|      9657|              248680|\n",
      "|    69558|     89537|              248680|\n",
      "|    54523|     58926|              112204|\n",
      "|    54523|      8465|              112204|\n",
      "|    54523|     81787|              112204|\n",
      "|    55894|     69575|              763412|\n",
      "|    55894|      9466|              763412|\n",
      "|    55894|     67179|              763412|\n",
      "|    55894|     94469|              763412|\n",
      "|    55894|      7969|              763412|\n",
      "|    55894|      8024|              763412|\n",
      "|    55894|     63505|              763412|\n",
      "+---------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friend_recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1987b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"event.message_from\").orderBy(F.col(\"event.message_ts\").desc())\n",
    "\n",
    "user_location = (\n",
    "    messages_df.withColumn(\"rank\", F.row_number().over(window))\n",
    "    .filter(F.col(\"rank\") == 1)\n",
    "    .select(\n",
    "        F.col(\"event.message_from\").alias(\"user_id\"),\n",
    "        F.col(\"lat\"),\n",
    "        F.col(\"lon\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "64d535df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 260:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|user_id|                lat|               lon|\n",
      "+-------+-------------------+------------------+\n",
      "|   NULL|-26.472576372776835|153.33902097729592|\n",
      "|    287| -33.53099196771466| 151.3645309475204|\n",
      "|    301|-11.833472609334132|131.66764401033888|\n",
      "|    311| -37.58271830542874|144.99881332011873|\n",
      "|    319| -37.27830535736941|144.57763024012436|\n",
      "|    330| -34.92303009477633|138.60480380997166|\n",
      "|    348| -42.46203022753594|147.74526183973532|\n",
      "|    358|-22.901596801404743|151.43839308895915|\n",
      "|    405| -32.55539550611397|116.05677089761832|\n",
      "|    424|-37.671066196368784| 145.9049365138819|\n",
      "|    441| -42.42589851097819|147.32535603694978|\n",
      "|    641| -32.28606920299048|151.75222641010603|\n",
      "|    662|-27.436733573971328|152.19560825478487|\n",
      "|    704|-31.030667395631074|116.11547342467769|\n",
      "|    729| -37.41720166047213| 145.4600139563115|\n",
      "|    787|-27.534953730073994| 153.7166065592272|\n",
      "|    822|-27.413513562198915|154.13706727185019|\n",
      "|    954|-33.452625135614085|151.44178427130765|\n",
      "|   1009| -31.06125008754974|116.10962611989154|\n",
      "|   1033| -35.23895504973037|149.33103448638735|\n",
      "+-------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b7ed0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_recommendations = (\n",
    "    friend_recommendations\n",
    "    .join(user_location, (friend_recommendations.user_left == user_location.user_id))\n",
    "    .select(\n",
    "        \"user_left\",\n",
    "        F.col(\"lat\").alias(\"left_lat\"),\n",
    "        F.col(\"lon\").alias(\"left_lon\"),\n",
    "        \"user_right\"\n",
    "    )\n",
    "    .join(user_location, (friend_recommendations.user_right == user_location.user_id))\n",
    "    .select(\n",
    "        \"user_left\",\n",
    "        F.col(\"left_lat\"),\n",
    "        F.col(\"left_lon\"),\n",
    "        \"user_right\",\n",
    "        F.col(\"lat\").alias(\"right_lat\"),\n",
    "        F.col(\"lon\").alias(\"right_lon\"),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"distance\",\n",
    "        haversine_udf(F.col(\"left_lat\"), F.col(\"left_lon\"), F.col(\"right_lat\"), F.col(\"right_lon\"))\n",
    "    )\n",
    "    .filter(F.col(\"distance\") <= 1)\n",
    "    .withColumn(\"processed_dttm\", F.lit(CUR_DATE))\n",
    "#     .select(\n",
    "#         \"user_left\",\n",
    "#         \"user_right\",\n",
    "#         \"zone_id\",\n",
    "#         \"local_time\"\n",
    "#     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bfdc8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+----------+---------+---------+--------+\n",
      "|user_left|left_lat|left_lon|user_right|right_lat|right_lon|distance|\n",
      "+---------+--------+--------+----------+---------+---------+--------+\n",
      "+---------+--------+--------+----------+---------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friend_recommendations_w_distance.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
